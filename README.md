

WikiGap: Promoting Epistemic Equity by Surfacing Knowledge Gaps Between English Wikipedia and Other Language Editions

This repository contains the Chrome extension and companion resources described in our paper:

WikiGap: Promoting Epistemic Equity by Surfacing Knowledge Gaps Between English Wikipedia and Other Language Editions

â¸»

ğŸ” Overview

WikiGap is a browser extension that reveals factual asymmetries between English Wikipedia and selected non-English editions (Chinese, French, Russian). It helps to:
	â€¢	Challenge the â€œEnglish-as-supersetâ€ assumption
	â€¢	Increase cross-lingual awareness and access
	â€¢	Support multilingual knowledge equity

All fact-extraction and comparison logic lives in the separate InfoGap pipeline **(WikiGap branch)**:

https://github.com/smfsamir/infogap

This repo focuses exclusively on the UI layerâ€”loading the pre-computed JSON files and presenting knowledge gaps in the page.


ğŸ—‚ï¸ Repository Structure

Path / File	Purpose
content.js	Core script injected into Wikipedia pages
manifest.json	Chrome extension manifest
wikigap/process_annotations.py	Converts InfoGap output into the concise topic.json format consumed by the extension
quiz_questions/	Sample multiple-choice questions from our user study
studyeval/ (git-ignored)	Notebooks & scripts for analyzing user-study data
data/	Place to drop the JSON files generated by InfoGap (see steps below)


â¸»

ğŸš€ Quick Start: Testing the Extension
	1.	Clone the repo

git clone https://github.com/aw814/WikiGap.git


	2.	Zip the contents of the cloned directory (zip the files inside, not the parent folder).
	3.	Load the unpacked extension in Chrome:
	â€¢	Navigate to chrome://extensions/
	â€¢	Toggle Developer mode (top-right)
	â€¢	Click Load unpacked, select the unzipped directory
	4.	Visit one of the sample English-language articles included in the dataset (e.g., Peking Duck, Philippine Adobo, Paella, Injera, Wiener Schnitzel). You should see WikiGap highlight cross-lingual facts in the sidebar.

â¸»

Below is an updated â€œUsing WikiGap on Additional Articlesâ€ section that spells out the two-stage InfoGap workflow and clarifies exactly which files you must place in this repo (data_pipeline/wikigap_data/json/{topic}.json).
You can replace the old section in README.md with the version below.

â¸»

ğŸŒ Using WikiGap on Additional Articles

WikiGapâ€™s UI expects a single, unified file per article (e.g., Peking_Duck.json). Producing that file is a two-step process inside the InfoGap repo:

Stage	Where it runs	Output file(s)	Purpose
1 A. Run the â€œcompleteâ€ InfoGap pipeline	infogap/	annotation_<DATE>_<ARTICLE_TOPIC>_<LANG>.json (one per language)	Raw fact-mismatch annotations generated by GPT
1 B. Post-process those annotation files (InfoGapâ€™s dedicated script)	infogap/	{ARTICLE_TOPIC}.json	Combines multi-language outputs into a single, easy-to-retrieve file for WikiGap

âœ¨ Note : Step 1 B is novel to the WikiGap projectâ€”it standardises the raw annotations for real-time look-ups inside the extension.

Step 1â€‚Generate {topic}.json via InfoGap
	1.	Run the main pipeline (InfoGap README â†’ run-multiple-topics, etc.).
This produces the per-language annotation_<â€¦>.json files.
	2.	Run the post-processing script provided in InfoGap (e.g.,

python postprocess/build_topic_json.py

or equivalent).
It collapses all annotation_*.json for a given article into one {topic}.json.

Step 2â€‚Copy Files Into This Repo

Place each final {topic}.json under:

WikiGap/
   â””â”€ json/
      â””â”€ {topic}.json     â† (one per article)

Step 3â€‚Refresh the Extension

Reload WikiGap in chrome://extensions/, then visit the corresponding English Wikipedia articleâ€”your new cross-lingual facts will surface automatically.



ğŸ“„ Paper

Preprint: https://arxiv.org/abs/2505.24195

â¸»

ğŸ¤ Citation

If you use this codebase or the accompanying datasets, please cite the paper above.
# WikiGap: Promoting Epistemic Equity by Surfacing Knowledge Gaps Between English Wikipedia and Other Language Editions

This repository contains the **Chrome extension** and companion resources described in our paper:

> **WikiGap: Promoting Epistemic Equity by Surfacing Knowledge Gaps Between English Wikipedia and Other Language Editions**

---

## ğŸ” Overview

WikiGap is a browser extension that reveals factual asymmetries between English Wikipedia and selected nonâ€‘English editions (Chinese, French, Russian). It helps to:

- Challenge the â€œEnglishâ€‘asâ€‘supersetâ€ assumption  
- Increase crossâ€‘lingual awareness and access  
- Support multilingual knowledge equity  

All factâ€‘extraction and comparison logic lives in the separate **InfoGap pipeline (WikiGap branch)**: <https://github.com/smfsamir/infogap>

This repo focuses exclusively on the **UI layer**â€”loading the preâ€‘computed JSON files and presenting knowledge gaps directly in the page.

---

## ğŸ—‚ï¸ Repository Structure

| Path / File                              | Purpose                                                                                                     |
|------------------------------------------|-------------------------------------------------------------------------------------------------------------|
| `content.js`                             | Core script injected into Wikipedia pages                                                                   |
| `manifest.json`                          | Chrome extension manifest                                                                                   |
| `wikigap/process_annotations.py`         | Converts InfoGap output into the concise `topic.json` format consumed by the extension                      |
| `quiz_questions/`                        | Sample multipleâ€‘choice questions from our user study                                                        |
| `studyeval/`Â (gitâ€‘ignored)               | Notebooks & scripts for analyzing userâ€‘study data                                                           |
| `data_pipeline/wikigap_data/json/`       | **Drop the final `{topic}.json` files** generated by InfoGap here                                           |

---

## ğŸš€ QuickÂ Start: Testing the Extension

1. **Clone** the repo  
   ```bash
   git clone https://github.com/aw814/WikiGap.git
   ```
2. **Zip** the *contents* of the cloned directory (zip the files inside, **not** the parent folder).  
3. **Load** the unpacked extension in Chrome:  
   - Navigate to `chrome://extensions/`  
   - Toggle **Developer mode** (topâ€‘right)  
   - Click **Load unpacked** and select the unzipped directory  
4. Visit one of the sample Englishâ€‘language articles included in the dataset (e.g., *PekingÂ Duck*, *PhilippineÂ Adobo*, *Paella*, *Injera*, *WienerÂ Schnitzel*). WikiGap should highlight crossâ€‘lingual facts in the sidebar.

---

## ğŸŒ Using WikiGap on Additional Articles

WikiGapâ€™s UI expects a **single, unified file** per article (e.g., `Peking_Duck.json`). Producing that file is a twoâ€‘step process *inside the InfoGap repo*:

| Stage | Where it runs | Output file(s) | Purpose |
|-------|---------------|----------------|---------|
| **1â€¯A.** Run the full InfoGap pipeline | `infogap/` | `annotation_<DATE>_<ARTICLE_TOPIC>_<LANG>.json` (one per language) | Raw factâ€‘mismatch annotations generated by GPT |
| **1â€¯B.** **Postâ€‘process** those annotation files | `infogap/` | `{ARTICLE_TOPIC}.json` | Combines multiâ€‘language outputs into a single, easyâ€‘toâ€‘retrieve file for WikiGap |

> **NoteÂ :** StepÂ 1â€¯B is novel to the WikiGap projectâ€”it standardises the raw annotations for realâ€‘time lookâ€‘ups inside the extension.

### 1. Generate `{topic}.json` via InfoGap

```bash
# inside the InfoGap repo
python main_complete_analysis.py run-multiple-topics   # produces annotation_*.json
python postprocess/build_topic_json.py                 # collapses into {topic}.json
```

### 2. Copy files into this repo

Place each final `{topic}.json` under:

```
WikiGap/
â””â”€ data_pipeline/
   â””â”€ wikigap_data/
      â””â”€ json/
         â””â”€ {topic}.json
```

### 3. Refresh the extension

Reload WikiGap in `chrome://extensions/`, then visit the corresponding English Wikipedia articleâ€”your new crossâ€‘lingual facts will surface automatically.

---

## ğŸ“„ Paper

Preprint available on arXiv: <https://arxiv.org/abs/2505.24195>

---

## ğŸ¤ Citation

If you use this codebase or the accompanying datasets, please cite the paper above.